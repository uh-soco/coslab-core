image_id,full_detect_labels_response,label_num,label_str,label_conf
2020_isnt_so_bad_after_all.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285ab1c8b0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'f044a8e0-f97d-407d-900c-d444e34b8390', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285ab60970>}",1,people_group,0.38671875
15_years_from_now.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa733a0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'b51aaa4e-bd80-448d-ba43-1e8ebd835f9f', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa73ee0>}",1,people_group,0.8125
13-3-10894973.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a1f0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a0a0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'a894395e-471c-4a8d-a3aa-b0572739f354', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa73790>}",1,others_,0.01953125
13-3-10894973.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a1f0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a0a0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'a894395e-471c-4a8d-a3aa-b0572739f354', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa73790>}",2,people_,0.52734375
All_my_homies_are_nocturnal.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a8b0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7ae80>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'c1a36d45-8fa1-4880-8124-d16fe77b5472', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa7af70>}",1,others_,0.00390625
All_my_homies_are_nocturnal.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a8b0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7ae80>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'c1a36d45-8fa1-4880-8124-d16fe77b5472', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa7af70>}",2,text_mag,0.78125
Homma_314291361989750_775367765882105_74310383c831cf33fd59e400d9cb8ac921478622d735226b962c8bff.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f1c0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f4c0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'a524255f-d1f4-484d-85b2-49df3d0186ed', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa9f760>}",1,others_,0.00390625
Homma_314291361989750_775367765882105_74310383c831cf33fd59e400d9cb8ac921478622d735226b962c8bff.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f1c0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f4c0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'a524255f-d1f4-484d-85b2-49df3d0186ed', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa9f760>}",2,text_,0.7109375
Big_brain.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a7c0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '1f23be47-859b-4040-b3e9-d17be2aa2435', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa7aee0>}",1,outdoor_,0.24609375
A_80s_aesthetic_inspo_that_no_one_asked_for_.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a3a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285ab018b0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'e744109b-55e6-43fb-862e-58165d656495', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa7a670>}",1,abstract_nonphoto,0.20703125
A_80s_aesthetic_inspo_that_no_one_asked_for_.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa7a3a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285ab018b0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'e744109b-55e6-43fb-862e-58165d656495', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa7a670>}",2,abstract_texture,0.25390625
Cant_tell.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa738e0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'b47bbc2b-b42c-4dfc-bdad-ffe149beb0bb', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa73880>}",1,people_many,0.75
80s_feels.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9fb80>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f2b0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'a8c742a4-558b-4e37-86fd-7c90350b88dd', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa736a0>}",1,outdoor_,0.015625
80s_feels.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9fb80>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f2b0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'a8c742a4-558b-4e37-86fd-7c90350b88dd', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa736a0>}",2,sky_cloud,0.546875
762020.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa9f7c0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'd4671134-484a-405b-acee-6f329569a02b', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa9fd30>}",1,plant_,0.3046875
13-3-7462317.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaac460>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '260c66cd-f799-4b5b-b36b-063f8696218f', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aa9feb0>}",1,indoor_court,0.97265625
39-6153665ddbaab6203d6.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaac5b0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '99373d88-dba7-49f5-8841-07184a97c4ea', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaacb50>}",1,others_,0.00390625
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34280>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34310>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34100>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34370>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '359103e6-e761-4f13-a829-7e0800096ab1', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaacfd0>}",1,abstract_,0.0234375
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34280>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34310>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34100>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34370>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '359103e6-e761-4f13-a829-7e0800096ab1', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaacfd0>}",2,building_doorwindows,0.15625
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34280>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34310>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34100>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34370>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '359103e6-e761-4f13-a829-7e0800096ab1', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaacfd0>}",3,others_,0.0078125
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34280>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34310>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34100>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aa34370>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '359103e6-e761-4f13-a829-7e0800096ab1', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaacfd0>}",4,outdoor_,0.00390625
04-06-19 at 20.13.44_(1).jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaacf40>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '0d8cfe56-c174-40c4-aaba-00ac368209cd', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaacca0>}",1,people_group,0.70703125
Confusing.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaacac0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaac370>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'bf934681-5c05-4e77-bb27-d7fa6d279972', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaac280>}",1,others_,0.00390625
Confusing.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaacac0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7f285aaac370>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'bf934681-5c05-4e77-bb27-d7fa6d279972', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7f285aaac280>}",2,people_,0.69140625
