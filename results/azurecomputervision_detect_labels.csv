image_id,full_detect_labels_response,label_num,label_str,label_conf
2020_isnt_so_bad_after_all.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee844940>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '6d6c8138-c4b2-4005-b7bc-0d1acf2c30a4', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee886910>}",1,people_group,0.38671875
15_years_from_now.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee79a340>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '4821f7d4-b674-4e18-b4eb-faed704e55bd', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee79ae80>}",1,people_group,0.8125
13-3-10894973.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a06a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0e50>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '1e706689-90e6-4d98-bfc4-c77c1ab8f45a', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee79afa0>}",1,others_,0.01953125
13-3-10894973.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a06a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0e50>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '1e706689-90e6-4d98-bfc4-c77c1ab8f45a', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee79afa0>}",2,people_,0.52734375
All_my_homies_are_nocturnal.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0850>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0e20>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '3cfdd164-cb97-4b4a-8a63-9f7610a66301', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7a0f10>}",1,others_,0.00390625
All_my_homies_are_nocturnal.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0850>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0e20>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '3cfdd164-cb97-4b4a-8a63-9f7610a66301', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7a0f10>}",2,text_mag,0.78125
Homma_314291361989750_775367765882105_74310383c831cf33fd59e400d9cb8ac921478622d735226b962c8bff.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7160>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7460>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '7cc4038d-0927-4974-8d3f-44bc4df6a772', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7c7700>}",1,others_,0.00390625
Homma_314291361989750_775367765882105_74310383c831cf33fd59e400d9cb8ac921478622d735226b962c8bff.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7160>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7460>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '7cc4038d-0927-4974-8d3f-44bc4df6a772', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7c7700>}",2,text_,0.7109375
Big_brain.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0a90>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '3acb005a-402a-42c0-9924-38f0c0ee7f7e', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7a0fd0>}",1,outdoor_,0.24609375
A_80s_aesthetic_inspo_that_no_one_asked_for_.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0340>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee829910>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '8a8cd278-81d2-4610-8c71-d421dc1504e3', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7a0520>}",1,abstract_nonphoto,0.20703125
A_80s_aesthetic_inspo_that_no_one_asked_for_.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7a0340>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee829910>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '8a8cd278-81d2-4610-8c71-d421dc1504e3', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7a0520>}",2,abstract_texture,0.25390625
Cant_tell.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee79a7f0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '3927c87f-6c51-45b9-8648-7ab0912c9efe', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee79a6a0>}",1,people_many,0.75
80s_feels.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c79a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7be0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'de89f18f-08a9-4663-bb63-414a17d09cb9', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee79a430>}",1,outdoor_,0.015625
80s_feels.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c79a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7be0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'de89f18f-08a9-4663-bb63-414a17d09cb9', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee79a430>}",2,sky_cloud,0.546875
762020.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7c7220>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '50e3f76c-bf59-4b2d-aeb6-2dd77c5f1889', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7c7cd0>}",1,plant_,0.3046875
13-3-7462317.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d2400>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '9284a8d4-8a94-44ad-805d-b8625e08055d', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7c7e50>}",1,indoor_court,0.97265625
39-6153665ddbaab6203d6.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d2550>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '7c351d4e-33b3-48c5-bb3e-26da69e19241', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d2af0>}",1,others_,0.00390625
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b220>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b2b0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b0a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b310>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '47166f78-b75c-4a48-b732-5117a4429e63', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d2f40>}",1,abstract_,0.0234375
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b220>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b2b0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b0a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b310>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '47166f78-b75c-4a48-b732-5117a4429e63', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d2f40>}",2,building_doorwindows,0.15625
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b220>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b2b0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b0a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b310>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '47166f78-b75c-4a48-b732-5117a4429e63', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d2f40>}",3,others_,0.0078125
abandoned_room.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b220>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b2b0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b0a0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee75b310>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '47166f78-b75c-4a48-b732-5117a4429e63', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d2f40>}",4,outdoor_,0.00390625
04-06-19 at 20.13.44_(1).jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d2df0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'afee8eaa-9fbb-4575-b836-5dad11c5f346', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d2c40>}",1,people_group,0.70703125
Confusing.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d25e0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d26d0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '020ac3dc-f94b-4bd4-a6d5-2e4a00b771a6', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d21f0>}",1,others_,0.00390625
Confusing.jpg,"{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d25e0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x7fa8ee7d26d0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '020ac3dc-f94b-4bd4-a6d5-2e4a00b771a6', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fa8ee7d21f0>}",2,people_,0.69140625
